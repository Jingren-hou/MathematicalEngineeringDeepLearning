{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Mathematical Engineering of Deep Learning\n",
    "\n",
    "## Practical 5 (Julia version)\n",
    "**For an R or Python version see the [course website](https://deeplearningmath.org/)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical we deal with a reduced version of the CIFAR10 dataset and train convolutional neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10\n",
    "See [CIFAR10 website](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(CIFAR10Fulltrain_x) = (32, 32, 3, 50000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"airplane\"\n",
       " \"automobile\"\n",
       " \"bird\"\n",
       " \"cat\"\n",
       " \"deer\"\n",
       " \"dog\"\n",
       " \"frog\"\n",
       " \"horse\"\n",
       " \"ship\"\n",
       " \"truck\""
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "CIFAR10Fulltrain_x, CIFAR10Fulltrain_y = CIFAR10.traindata()\n",
    "CIFAR10Fulltest_x,  CIFAR10Fulltest_y  = CIFAR10.testdata()\n",
    "@show size(CIFAR10Fulltrain_x)\n",
    "classNames = CIFAR10.classnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(CIFAR10Filteredtrain_y) = 15000\n",
      "length(CIFAR10Filteredtest_y) = 3000\n"
     ]
    }
   ],
   "source": [
    "#use only \"airplane\", \"cat\" and \"truck\" to make the problem \"easier and quicker\" for the practical\n",
    "usedLabels = [0,3,9]\n",
    "trainFilter = [y ∈ usedLabels for y in CIFAR10Fulltrain_y]  #use \\in +[TAB] to make ∈ (element of set checking)\n",
    "testFilter = [y ∈ usedLabels for y in CIFAR10Fulltest_y]\n",
    "CIFAR10Filteredtrain_x, CIFAR10Filteredtrain_y = CIFAR10Fulltrain_x[:,:,:,trainFilter], CIFAR10Fulltrain_y[trainFilter]\n",
    "CIFAR10Filteredtest_x,  CIFAR10Filteredtest_y  = CIFAR10Fulltest_x[:,:,:,testFilter],  CIFAR10Fulltest_y[testFilter];\n",
    "@show length(CIFAR10Filteredtrain_y)\n",
    "@show length(CIFAR10Filteredtest_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLength = 2000\n",
    "validateLength = 1000;\n",
    "trainRange = 1:trainLength\n",
    "validateRange = (trainLength+1):(trainLength+validateLength);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: onehotbatch\n",
    "\n",
    "x_train = CIFAR10Filteredtrain_x[:,:,:,trainRange]\n",
    "x_validate = CIFAR10Filteredtrain_x[:,:,:,validateRange]\n",
    "x_test = CIFAR10Filteredtest_x\n",
    "\n",
    "y_train = onehotbatch(CIFAR10Filteredtrain_y[trainRange], usedLabels)\n",
    "y_validate = onehotbatch(CIFAR10Filteredtrain_y[validateRange], usedLabels)\n",
    "y_test = onehotbatch(CIFAR10Filteredtest_y, usedLabels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux: onehotbatch\n",
    "batchSize = 100\n",
    "\n",
    "x_train_batches = [x_train[:, :, :, r] for r in Iterators.partition(trainRange, batchSize)];\n",
    "y_train_batches = [y_train[:,r] for r in Iterators.partition(trainRange,batchSize)];\n",
    "\n",
    "numMiniBatches = length(x_train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 3=>8, relu), BatchNorm(8), #181, Conv((3, 3), 8=>4, relu), BatchNorm(4), #182, flatten, Dense(196, 80, relu), Dropout(0.5), Dense(80, 40, relu), Dropout(0.5), Dense(40, 3), softmax)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "function buildModel1()\n",
    "    Chain(  #Assuming 32x32x3 input layer (like CIFAR10)\n",
    "      Conv((3, 3), 3 => 8, relu, pad=(1, 1), stride=(1, 1)),   #32x32x8 convolutional layer\n",
    "      BatchNorm(8),\n",
    "      x -> maxpool(x, (2, 2)),  #16x16x8\n",
    "      Conv((3, 3), 8 => 4, relu, pad=(0, 0), stride=(1, 1)), #14x14x4  convolutional layer\n",
    "      BatchNorm(4),\n",
    "      x -> maxpool(x, (2, 2)), #7x7x4 ,\n",
    "      flatten,  #196 neurons\n",
    "      Dense(196, 80, relu),\n",
    "      Dropout(0.5),\n",
    "      Dense(80, 40, relu), #40 neurons\n",
    "      Dropout(0.5),\n",
    "      Dense(40, 3), #3 output neruons\n",
    "      softmax)\n",
    "end\n",
    "\n",
    "model1 = buildModel1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×32×3×1 Array{N0f8,4} with eltype FixedPointNumbers.Normed{UInt8,8}:\n",
       "[:, :, 1, 1] =\n",
       " 0.604  0.549  0.549  0.533  0.506  …  0.682  0.643  0.686  0.647  0.639\n",
       " 0.494  0.569  0.545  0.537  0.553     0.553  0.553  0.612  0.612  0.62\n",
       " 0.412  0.49   0.451  0.478  0.533     0.173  0.451  0.604  0.624  0.639\n",
       " 0.4    0.486  0.576  0.518  0.729     0.169  0.443  0.576  0.514  0.569\n",
       " 0.49   0.588  0.541  0.592  0.843     0.224  0.455  0.608  0.369  0.169\n",
       " 0.608  0.596  0.518  0.71   0.792  …  0.204  0.447  0.631  0.4    0.075\n",
       " 0.675  0.682  0.667  0.796  0.643     0.173  0.443  0.627  0.424  0.078\n",
       " 0.706  0.698  0.698  0.816  0.588     0.188  0.455  0.655  0.502  0.29\n",
       " 0.557  0.525  0.671  0.816  0.541     0.31   0.486  0.647  0.604  0.525\n",
       " 0.435  0.431  0.753  0.796  0.467     0.678  0.584  0.596  0.612  0.467\n",
       " 0.416  0.522  0.859  0.702  0.369  …  0.851  0.627  0.639  0.714  0.431\n",
       " 0.427  0.639  0.918  0.663  0.424     0.651  0.557  0.643  0.702  0.388\n",
       " 0.482  0.753  0.898  0.643  0.424     0.38   0.384  0.522  0.49   0.239\n",
       " ⋮                                  ⋱                       ⋮      \n",
       " 0.455  0.557  0.694  0.718  0.522  …  0.31   0.271  0.243  0.137  0.024\n",
       " 0.4    0.376  0.396  0.475  0.49      0.286  0.278  0.2    0.082  0.039\n",
       " 0.373  0.388  0.396  0.357  0.4       0.282  0.271  0.173  0.055  0.098\n",
       " 0.353  0.373  0.345  0.369  0.384     0.329  0.294  0.153  0.043  0.2\n",
       " 0.282  0.349  0.404  0.357  0.345     0.341  0.31   0.169  0.055  0.267\n",
       " 0.235  0.314  0.369  0.302  0.314  …  0.369  0.463  0.4    0.231  0.353\n",
       " 0.22   0.255  0.255  0.271  0.353     0.282  0.337  0.216  0.192  0.455\n",
       " 0.302  0.329  0.325  0.38   0.369     0.169  0.333  0.125  0.212  0.525\n",
       " 0.369  0.361  0.353  0.345  0.271     0.133  0.122  0.09   0.318  0.549\n",
       " 0.357  0.376  0.31   0.298  0.278     0.404  0.302  0.165  0.404  0.561\n",
       " 0.341  0.302  0.267  0.251  0.267  …  0.373  0.267  0.239  0.482  0.561\n",
       " 0.31   0.278  0.263  0.278  0.341     0.486  0.369  0.365  0.514  0.561\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.694  0.627  0.608  0.576  0.537  …  0.643  0.608  0.655  0.604  0.58\n",
       " 0.537  0.6    0.573  0.557  0.573     0.537  0.545  0.604  0.596  0.58\n",
       " 0.408  0.49   0.451  0.475  0.545     0.18   0.467  0.627  0.631  0.612\n",
       " 0.396  0.506  0.6    0.522  0.729     0.161  0.443  0.6    0.51   0.529\n",
       " 0.514  0.631  0.588  0.616  0.863     0.2    0.424  0.6    0.345  0.125\n",
       " 0.651  0.643  0.569  0.757  0.847  …  0.18   0.412  0.604  0.361  0.035\n",
       " 0.745  0.737  0.722  0.871  0.737     0.145  0.424  0.639  0.42   0.055\n",
       " 0.78   0.741  0.741  0.89   0.698     0.145  0.439  0.678  0.506  0.267\n",
       " 0.612  0.545  0.69   0.875  0.635     0.271  0.482  0.647  0.584  0.49\n",
       " 0.471  0.435  0.765  0.859  0.573     0.675  0.612  0.596  0.592  0.431\n",
       " 0.42   0.498  0.855  0.761  0.478  …  0.792  0.612  0.635  0.694  0.396\n",
       " 0.408  0.612  0.914  0.722  0.537     0.537  0.502  0.639  0.686  0.365\n",
       " 0.475  0.753  0.929  0.729  0.545     0.361  0.392  0.541  0.506  0.247\n",
       " ⋮                                  ⋱                       ⋮      \n",
       " 0.459  0.561  0.694  0.718  0.525  …  0.314  0.278  0.251  0.145  0.024\n",
       " 0.396  0.38   0.4    0.482  0.502     0.29   0.29   0.208  0.086  0.035\n",
       " 0.373  0.396  0.404  0.369  0.42      0.275  0.278  0.169  0.047  0.086\n",
       " 0.349  0.376  0.349  0.38   0.408     0.306  0.298  0.141  0.024  0.176\n",
       " 0.275  0.349  0.404  0.369  0.361     0.333  0.322  0.173  0.051  0.251\n",
       " 0.235  0.318  0.373  0.314  0.322  …  0.365  0.475  0.424  0.251  0.353\n",
       " 0.224  0.263  0.263  0.282  0.365     0.251  0.318  0.22   0.192  0.443\n",
       " 0.306  0.337  0.337  0.392  0.38      0.133  0.306  0.102  0.188  0.498\n",
       " 0.376  0.373  0.365  0.357  0.286     0.129  0.106  0.055  0.282  0.51\n",
       " 0.373  0.388  0.322  0.306  0.286     0.424  0.302  0.133  0.365  0.522\n",
       " 0.353  0.314  0.275  0.259  0.275  …  0.384  0.259  0.208  0.447  0.525\n",
       " 0.318  0.286  0.271  0.286  0.349     0.482  0.345  0.325  0.475  0.522\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.733  0.663  0.643  0.608  0.565  …  0.667  0.627  0.651  0.502  0.471\n",
       " 0.533  0.604  0.584  0.573  0.596     0.588  0.596  0.627  0.51   0.478\n",
       " 0.373  0.463  0.439  0.475  0.557     0.22   0.518  0.667  0.557  0.522\n",
       " 0.388  0.518  0.624  0.545  0.745     0.188  0.475  0.639  0.498  0.49\n",
       " 0.545  0.678  0.635  0.655  0.89      0.224  0.459  0.647  0.373  0.125\n",
       " 0.706  0.686  0.604  0.776  0.875  …  0.208  0.451  0.671  0.408  0.047\n",
       " 0.824  0.784  0.745  0.878  0.765     0.173  0.463  0.706  0.471  0.075\n",
       " 0.839  0.769  0.753  0.902  0.725     0.18   0.486  0.729  0.537  0.275\n",
       " 0.612  0.537  0.686  0.882  0.663     0.294  0.525  0.682  0.596  0.478\n",
       " 0.431  0.4    0.741  0.851  0.588     0.659  0.624  0.627  0.604  0.42\n",
       " 0.384  0.471  0.851  0.776  0.522  …  0.761  0.612  0.667  0.702  0.388\n",
       " 0.4    0.612  0.933  0.769  0.604     0.537  0.522  0.675  0.702  0.357\n",
       " 0.459  0.733  0.922  0.745  0.576     0.424  0.455  0.596  0.529  0.243\n",
       " ⋮                                  ⋱                       ⋮      \n",
       " 0.404  0.533  0.698  0.753  0.573  …  0.392  0.361  0.302  0.173  0.043\n",
       " 0.325  0.333  0.38   0.486  0.514     0.361  0.376  0.271  0.118  0.047\n",
       " 0.298  0.329  0.361  0.341  0.396     0.349  0.361  0.224  0.071  0.086\n",
       " 0.31   0.341  0.322  0.361  0.392     0.384  0.376  0.184  0.035  0.165\n",
       " 0.271  0.337  0.388  0.345  0.329     0.412  0.396  0.224  0.078  0.263\n",
       " 0.239  0.302  0.337  0.259  0.259  …  0.416  0.529  0.478  0.302  0.396\n",
       " 0.212  0.235  0.212  0.216  0.286     0.263  0.341  0.251  0.227  0.478\n",
       " 0.282  0.298  0.275  0.314  0.29      0.129  0.306  0.114  0.204  0.522\n",
       " 0.329  0.314  0.294  0.275  0.196     0.145  0.114  0.055  0.286  0.533\n",
       " 0.278  0.306  0.251  0.251  0.235     0.482  0.329  0.141  0.376  0.545\n",
       " 0.278  0.243  0.216  0.208  0.224  …  0.435  0.286  0.224  0.471  0.557\n",
       " 0.275  0.239  0.216  0.231  0.29      0.522  0.369  0.357  0.514  0.565"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleImage = x_train_batches[1][:,:,:,1:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Array{Float32,2}:\n",
       " 0.16442631\n",
       " 0.47440314\n",
       " 0.3611705"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(sampleImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(model1) #The number of `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 1 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 32, 8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 2 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 32, 8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 3 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 16, 8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 4 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 14, 4, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 5 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 14, 4, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 6 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 4, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 7 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(196, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 8 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 9 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 10 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 11 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 12 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 13 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function debugModel(model)\n",
    "    for topLayer = 1:length(model)\n",
    "        print(\"Output after $topLayer layers\"); flush(stdout)\n",
    "        outputSize = size(model[1:topLayer](sampleImage))\n",
    "        display(outputSize)\n",
    "    end\n",
    "end\n",
    "debugModel(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Modify the model to have (5x5) convolutions in the first layer with padding of 2 and without a max pooling layer after the second convolutional layer. You'll need to update the number of neurons in the dense layers. The use `debugModel()` to print the size evolution of your model. Call this model, `model2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((5, 5), 3=>8, relu), BatchNorm(8), #185, Conv((3, 3), 8=>4, relu), BatchNorm(4), flatten, Dense(676, 80, relu), Dropout(0.5), Dense(80, 40, relu), Dropout(0.5), Dense(40, 3), softmax)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLUTION:\n",
    "\n",
    "model2 = Chain(  #Assuming 32x32x3 input layer (like CIFAR10)\n",
    "  Conv((5, 5), 3 => 8, relu, pad=(1, 1), stride=(1, 1)),   #30x3-x8 convolutional layer\n",
    "  BatchNorm(8),\n",
    "  x -> maxpool(x, (2, 2)),  #15x15x8\n",
    "  Conv((3, 3), 8 => 4, relu, pad=(0, 0), stride=(1, 1)), #13x13x4  convolutional layer\n",
    "  BatchNorm(4),\n",
    "  flatten,  #676 neurons\n",
    "  Dense(676, 80, relu),\n",
    "  Dropout(0.5),\n",
    "  Dense(80, 40, relu), #40 neurons\n",
    "  Dropout(0.5),\n",
    "  Dense(40, 3), #3 output neruons\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 1 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30, 8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 2 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30, 8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 3 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15, 8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 4 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 13, 4, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 5 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 13, 4, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 6 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(676, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 7 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 8 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 9 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 10 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 11 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 12 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "debugModel(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: crossentropy\n",
    "loss(x, y, model) = crossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1330861f0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x_train_batches[1],y_train_batches[1],model1) #Loss on first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1863401f0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x_train,y_train,model1) #Loss on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux: onecold\n",
    "using Statistics\n",
    "accuracy(x, y, model) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.359"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_validate,y_validate,model1) #should be around 0.33 as model is garbage at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of computing the gradient (automatic differentiantion) on the first minibatch\n",
    "gs = gradient(()->loss(x_train_batches[1],y_train_batches[1],model1),params(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of a single update step of the optimizer\n",
    "using Flux: update!\n",
    "η = 0.002\n",
    "opt = ADAM(η)\n",
    "update!(opt,params(model1),gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainModel (generic function with 1 method)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Dates\n",
    "function trainModel(model; epochs = 20, η = 0.005)\n",
    "    opt = ADAM(η)\n",
    "    for ep in 1:epochs #Loop over epochs\n",
    "        \n",
    "        for bi in 1:numMiniBatches #Loop over minibatches\n",
    "            gs = gradient(()->loss(x_train_batches[bi],y_train_batches[bi],model),params(model))\n",
    "            update!(opt,params(model),gs)\n",
    "        end\n",
    "        \n",
    "        acc = accuracy(x_validate,y_validate,model)\n",
    "        ls = loss(x_train,y_train,model)\n",
    "        time = Dates.format(now(), \"HH:MM:SS\")\n",
    "        @show ep, time, acc, ls\n",
    "    end\n",
    "    \n",
    "    return model\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ep, time, acc, ls) = (1, \"22:23:14\", 0.519, 0.95736796f0)\n",
      "(ep, time, acc, ls) = (2, \"22:23:17\", 0.664, 0.73524684f0)\n",
      "(ep, time, acc, ls) = (3, \"22:23:19\", 0.71, 0.6201586f0)\n",
      "(ep, time, acc, ls) = (4, \"22:23:22\", 0.746, 0.5352092f0)\n",
      "(ep, time, acc, ls) = (5, \"22:23:24\", 0.754, 0.53658116f0)\n",
      "(ep, time, acc, ls) = (6, \"22:23:27\", 0.774, 0.4776568f0)\n",
      "(ep, time, acc, ls) = (7, \"22:23:29\", 0.78, 0.4284192f0)\n",
      "(ep, time, acc, ls) = (8, \"22:23:32\", 0.762, 0.4941161f0)\n",
      "(ep, time, acc, ls) = (9, \"22:23:34\", 0.662, 0.7206606f0)\n",
      "(ep, time, acc, ls) = (10, \"22:23:37\", 0.722, 0.5078989f0)\n",
      "(ep, time, acc, ls) = (11, \"22:23:39\", 0.777, 0.43756983f0)\n",
      "(ep, time, acc, ls) = (12, \"22:23:42\", 0.756, 0.5166903f0)\n",
      "(ep, time, acc, ls) = (13, \"22:23:44\", 0.794, 0.38723493f0)\n",
      "(ep, time, acc, ls) = (14, \"22:23:46\", 0.735, 0.46121362f0)\n",
      "(ep, time, acc, ls) = (15, \"22:23:49\", 0.679, 0.7666417f0)\n",
      "(ep, time, acc, ls) = (16, \"22:23:51\", 0.807, 0.30085725f0)\n",
      "(ep, time, acc, ls) = (17, \"22:23:54\", 0.808, 0.29053882f0)\n",
      "(ep, time, acc, ls) = (18, \"22:23:57\", 0.787, 0.29030287f0)\n",
      "(ep, time, acc, ls) = (19, \"22:23:59\", 0.796, 0.2968036f0)\n",
      "(ep, time, acc, ls) = (20, \"22:24:02\", 0.806, 0.23582563f0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 3=>8, relu), BatchNorm(8), #181, Conv((3, 3), 8=>4, relu), BatchNorm(4), #182, flatten, Dense(196, 80, relu), Dropout(0.5), Dense(80, 40, relu), Dropout(0.5), Dense(40, 3), softmax)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedModel = trainModel(buildModel1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testModel (generic function with 1 method)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel(model) = accuracy(x_test,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8086666666666666"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel(trainedModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Attempt to create a different model archiecture - use two additional convolutional layer. Try to maximize the validation accuracy and we'll see in class who gets the best test accuracy (you can only check the test accuracy once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 3=>8, relu), BatchNorm(8), #181, Conv((3, 3), 8=>4, relu), BatchNorm(4), #182, flatten, Dense(196, 80, relu), Dropout(0.5), Dense(80, 40, relu), Dropout(0.5), Dense(40, 3), softmax)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solution (example)\n",
    "function buildModel3()\n",
    "    Chain(  #Assuming 32x32x3 input layer (like CIFAR10)\n",
    "      Conv((5, 5), 3 => 10, relu, pad=(1, 1), stride=(1, 1)),  \n",
    "      BatchNorm(10),\n",
    "      x -> maxpool(x, (2, 2)), \n",
    "      Conv((3, 3), 10 => 6, relu, pad=(1, 1), stride=(1, 1)), \n",
    "      BatchNorm(6),\n",
    "      x -> maxpool(x, (2, 2)), \n",
    "      Conv((3, 3), 6 => 6, relu, pad=(1, 1), stride=(1, 1)),\n",
    "      BatchNorm(6),\n",
    "      Conv((3, 3), 6 => 6, relu, pad=(1, 1), stride=(1, 1)), \n",
    "      BatchNorm(6),        \n",
    "      flatten, \n",
    "      Dense(294, 120, relu),\n",
    "      Dropout(0.5),\n",
    "      Dense(120, 60, relu),\n",
    "      Dropout(0.5),\n",
    "      Dense(60, 3), #3 output neruons\n",
    "      softmax)\n",
    "end\n",
    "\n",
    "model1 = buildModel1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 1 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30, 10, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 2 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30, 10, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 3 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15, 10, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 4 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 5 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 6 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 7 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 8 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 9 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 10 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7, 6, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 11 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(294, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 12 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 13 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 14 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 15 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 16 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after 17 layers"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "debugModel(buildModel3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ep, time, acc, ls) = (1, \"22:38:30\", 0.499, 0.99232835f0)\n",
      "(ep, time, acc, ls) = (2, \"22:38:36\", 0.608, 0.89747524f0)\n",
      "(ep, time, acc, ls) = (3, \"22:38:43\", 0.642, 0.8235785f0)\n",
      "(ep, time, acc, ls) = (4, \"22:38:50\", 0.655, 0.720899f0)\n",
      "(ep, time, acc, ls) = (5, \"22:38:56\", 0.706, 0.6534424f0)\n",
      "(ep, time, acc, ls) = (6, \"22:39:03\", 0.734, 0.5993063f0)\n",
      "(ep, time, acc, ls) = (7, \"22:39:09\", 0.727, 0.5949997f0)\n",
      "(ep, time, acc, ls) = (8, \"22:39:16\", 0.74, 0.56174f0)\n",
      "(ep, time, acc, ls) = (9, \"22:39:22\", 0.75, 0.4936087f0)\n",
      "(ep, time, acc, ls) = (10, \"22:39:29\", 0.767, 0.49218863f0)\n",
      "(ep, time, acc, ls) = (11, \"22:39:36\", 0.753, 0.4795915f0)\n",
      "(ep, time, acc, ls) = (12, \"22:39:43\", 0.773, 0.44230872f0)\n",
      "(ep, time, acc, ls) = (13, \"22:39:49\", 0.767, 0.41371825f0)\n",
      "(ep, time, acc, ls) = (14, \"22:39:56\", 0.77, 0.39146912f0)\n",
      "(ep, time, acc, ls) = (15, \"22:40:03\", 0.778, 0.37203264f0)\n",
      "(ep, time, acc, ls) = (16, \"22:40:10\", 0.795, 0.3630161f0)\n",
      "(ep, time, acc, ls) = (17, \"22:40:16\", 0.778, 0.35663137f0)\n",
      "(ep, time, acc, ls) = (18, \"22:40:23\", 0.8, 0.32497242f0)\n",
      "(ep, time, acc, ls) = (19, \"22:40:30\", 0.77, 0.34493834f0)\n",
      "(ep, time, acc, ls) = (20, \"22:40:36\", 0.795, 0.32511535f0)\n",
      "(ep, time, acc, ls) = (21, \"22:40:43\", 0.786, 0.3202936f0)\n",
      "(ep, time, acc, ls) = (22, \"22:40:49\", 0.789, 0.36133564f0)\n",
      "(ep, time, acc, ls) = (23, \"22:40:56\", 0.792, 0.25684845f0)\n",
      "(ep, time, acc, ls) = (24, \"22:41:02\", 0.752, 0.3485869f0)\n",
      "(ep, time, acc, ls) = (25, \"22:41:08\", 0.805, 0.26026398f0)\n",
      "(ep, time, acc, ls) = (26, \"22:41:15\", 0.802, 0.21604046f0)\n",
      "(ep, time, acc, ls) = (27, \"22:41:21\", 0.796, 0.19742194f0)\n",
      "(ep, time, acc, ls) = (28, \"22:41:28\", 0.806, 0.20460668f0)\n",
      "(ep, time, acc, ls) = (29, \"22:41:34\", 0.791, 0.25495258f0)\n",
      "(ep, time, acc, ls) = (30, \"22:41:41\", 0.802, 0.17508718f0)\n",
      "(ep, time, acc, ls) = (31, \"22:41:47\", 0.781, 0.30455926f0)\n",
      "(ep, time, acc, ls) = (32, \"22:41:54\", 0.781, 0.18255225f0)\n",
      "(ep, time, acc, ls) = (33, \"22:42:00\", 0.789, 0.15892737f0)\n",
      "(ep, time, acc, ls) = (34, \"22:42:06\", 0.79, 0.13271438f0)\n",
      "(ep, time, acc, ls) = (35, \"22:42:13\", 0.792, 0.13735172f0)\n",
      "(ep, time, acc, ls) = (36, \"22:42:20\", 0.772, 0.18346053f0)\n",
      "(ep, time, acc, ls) = (37, \"22:42:26\", 0.784, 0.17407049f0)\n",
      "(ep, time, acc, ls) = (38, \"22:42:33\", 0.792, 0.15672377f0)\n",
      "(ep, time, acc, ls) = (39, \"22:42:39\", 0.793, 0.10307606f0)\n",
      "(ep, time, acc, ls) = (40, \"22:42:46\", 0.797, 0.14958724f0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(Conv((5, 5), 3=>10, relu), BatchNorm(10), #343, Conv((3, 3), 10=>6, relu), BatchNorm(6), #344, Conv((3, 3), 6=>6, relu), BatchNorm(6), Conv((3, 3), 6=>6, relu), BatchNorm(6), flatten, Dense(294, 120, relu), Dropout(0.5), Dense(120, 60, relu), Dropout(0.5), Dense(60, 3), softmax)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedModel = trainModel(buildModel3(),η = 0.001, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7856666666666666"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel(trainedModel)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
